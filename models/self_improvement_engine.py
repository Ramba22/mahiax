"""
Self-Improvement Engine for MAHIA-X
Implements self-learning from user interactions and adaptive feedback mechanisms
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from collections import OrderedDict, defaultdict
import time
import json
import hashlib
from datetime import datetime

# Conditional imports
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

class FeedbackAnalyzer:
    """Analyzes user feedback to identify improvement opportunities"""
    
    def __init__(self, confidence_threshold: float = 0.8):
        """
        Initialize feedback analyzer
        
        Args:
            confidence_threshold: Threshold for confidence-based learning
        """
        self.confidence_threshold = confidence_threshold
        self.feedback_history = OrderedDict()
        self.improvement_opportunities = defaultdict(list)
        self.accuracy_tracker = []
        
    def analyze_response_quality(self, response: str, user_feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze response quality based on user feedback
        
        Args:
            response: Model response
            user_feedback: User feedback dictionary
            
        Returns:
            Quality analysis results
        """
        # Extract feedback metrics
        accuracy_rating = user_feedback.get("accuracy", 0.5)
        completeness_rating = user_feedback.get("completeness", 0.5)
        helpfulness_rating = user_feedback.get("helpfulness", 0.5)
        user_correction = user_feedback.get("correction", "")
        
        # Calculate overall quality score
        quality_score = (accuracy_rating + completeness_rating + helpfulness_rating) / 3.0
        
        # Identify issues
        issues = []
        if accuracy_rating < 0.7:
            issues.append("accuracy")
        if completeness_rating < 0.7:
            issues.append("completeness")
        if helpfulness_rating < 0.7:
            issues.append("helpfulness")
        if user_correction:
            issues.append("correction_needed")
            
        # Determine if self-improvement is needed
        needs_improvement = quality_score < self.confidence_threshold or len(issues) > 0
        
        analysis = {
            "quality_score": quality_score,
            "issues": issues,
            "needs_improvement": needs_improvement,
            "accuracy_rating": accuracy_rating,
            "completeness_rating": completeness_rating,
            "helpfulness_rating": helpfulness_rating,
            "user_correction": user_correction
        }
        
        return analysis
        
    def identify_improvement_opportunities(self, query: str, response: str, 
                                         analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Identify specific improvement opportunities
        
        Args:
            query: User query
            response: Model response
            analysis: Quality analysis results
            
        Returns:
            List of improvement opportunities
        """
        opportunities = []
        
        # Check for accuracy issues
        if "accuracy" in analysis["issues"]:
            opportunities.append({
                "type": "accuracy_improvement",
                "priority": "high",
                "description": "Response contains factual inaccuracies",
                "query_pattern": self._extract_query_pattern(query),
                "suggested_correction": analysis.get("user_correction", "")
            })
            
        # Check for completeness issues
        if "completeness" in analysis["issues"]:
            opportunities.append({
                "type": "completeness_improvement",
                "priority": "medium",
                "description": "Response is incomplete or missing key information",
                "query_pattern": self._extract_query_pattern(query),
                "missing_aspects": self._identify_missing_aspects(query, response)
            })
            
        # Check for helpfulness issues
        if "helpfulness" in analysis["issues"]:
            opportunities.append({
                "type": "helpfulness_improvement",
                "priority": "medium",
                "description": "Response is not helpful for user's needs",
                "query_intent": self._identify_query_intent(query),
                "better_approach": "Provide more targeted information"
            })
            
        return opportunities
        
    def _extract_query_pattern(self, query: str) -> str:
        """Extract pattern from query for categorization"""
        # Simple keyword-based pattern extraction
        keywords = query.lower().split()[:5]  # First 5 words
        return " ".join(keywords)
        
    def _identify_missing_aspects(self, query: str, response: str) -> List[str]:
        """Identify potentially missing aspects in response"""
        # Simple heuristic-based approach
        query_keywords = set(query.lower().split())
        response_keywords = set(response.lower().split())
        
        # Common question words that might indicate missing info
        question_indicators = {"what", "how", "why", "when", "where", "who", "which"}
        missing = []
        
        for indicator in question_indicators:
            if indicator in query_keywords and indicator not in response_keywords:
                missing.append(indicator)
                
        return missing
        
    def _identify_query_intent(self, query: str) -> str:
        """Identify the intent behind the query"""
        query_lower = query.lower()
        
        if any(word in query_lower for word in ["how to", "steps", "guide", "tutorial"]):
            return "instructional"
        elif any(word in query_lower for word in ["what is", "define", "explain", "meaning"]):
            return "informational"
        elif any(word in query_lower for word in ["best", "compare", "recommend", "suggest"]):
            return "recommendational"
        else:
            return "general"


class AdaptiveLearningModule(nn.Module):
    """Adaptive learning module that adjusts to new data and user behavior"""
    
    def __init__(self, input_dim: int = 768, hidden_dim: int = 256, output_dim: int = 128):
        """
        Initialize adaptive learning module
        
        Args:
            input_dim: Input dimension
            hidden_dim: Hidden layer dimension
            output_dim: Output dimension
        """
        super().__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        
        # Adaptive layers
        self.adaptation_network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim),
            nn.Tanh()
        )
        
        # Performance tracking
        self.performance_history = []
        self.adaptation_count = 0
        
        self._init_weights()
        
    def _init_weights(self):
        """Initialize network weights"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                nn.init.constant_(m.bias, 0.0)
                
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through adaptation network
        
        Args:
            x: Input tensor
            
        Returns:
            Adapted output tensor
        """
        return self.adaptation_network(x)
        
    def adapt_to_feedback(self, feedback_vector: torch.Tensor, 
                         performance_delta: float) -> float:
        """
        Adapt model based on feedback
        
        Args:
            feedback_vector: Vector representing feedback
            performance_delta: Change in performance metric
            
        Returns:
            Adaptation loss
        """
        if not TORCH_AVAILABLE:
            return 0.0
            
        # Simple adaptation mechanism
        # In a real implementation, this would involve more sophisticated adaptation
        self.performance_history.append(performance_delta)
        self.adaptation_count += 1
        
        # Calculate adaptation loss (simplified)
        with torch.no_grad():
            adapted_output = self.forward(feedback_vector)
            target = feedback_vector + (performance_delta * 0.1)  # Simple target adjustment
            
            if target.shape == adapted_output.shape:
                loss = torch.mean((adapted_output - target) ** 2)
                return loss.item()
                
        return 0.0


class SelfImprovementEngine:
    """Main self-improvement engine for continuous learning and adaptation"""
    
    def __init__(self, model_dim: int = 768):
        """
        Initialize self-improvement engine
        
        Args:
            model_dim: Model dimension for adaptation modules
        """
        self.model_dim = model_dim
        self.feedback_analyzer = FeedbackAnalyzer()
        self.adaptive_module = AdaptiveLearningModule(model_dim, model_dim // 3, model_dim // 6)
        
        # Learning components
        self.knowledge_base = OrderedDict()
        self.interaction_history = OrderedDict()
        self.improvement_log = OrderedDict()
        
        # Performance tracking
        self.self_improvement_stats = {
            "total_interactions": 0,
            "improvement_opportunities": 0,
            "successful_adaptations": 0,
            "feedback_quality_score": 0.0
        }
        
        print(f"‚úÖ SelfImprovementEngine initialized with model_dim: {model_dim}")
        
    def process_user_interaction(self, interaction_id: str, query: str, 
                               response: str, user_feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process user interaction and identify improvement opportunities
        
        Args:
            interaction_id: Unique identifier for interaction
            query: User query
            response: Model response
            user_feedback: User feedback dictionary
            
        Returns:
            Processing results
        """
        # Store interaction
        interaction_data = {
            "interaction_id": interaction_id,
            "query": query,
            "response": response,
            "user_feedback": user_feedback,
            "timestamp": time.time()
        }
        
        self.interaction_history[interaction_id] = interaction_data
        self.self_improvement_stats["total_interactions"] += 1
        
        # Analyze response quality
        quality_analysis = self.feedback_analyzer.analyze_response_quality(
            response, user_feedback
        )
        
        # Update accuracy tracker
        self.self_improvement_stats["feedback_quality_score"] = (
            (self.self_improvement_stats["feedback_quality_score"] * 
             (self.self_improvement_stats["total_interactions"] - 1) + 
             quality_analysis["quality_score"]) / 
            self.self_improvement_stats["total_interactions"]
        )
        
        # Identify improvement opportunities
        opportunities = self.feedback_analyzer.identify_improvement_opportunities(
            query, response, quality_analysis
        )
        
        self.self_improvement_stats["improvement_opportunities"] += len(opportunities)
        
        # Store opportunities
        if opportunities:
            self.improvement_log[interaction_id] = {
                "timestamp": time.time(),
                "quality_analysis": quality_analysis,
                "opportunities": opportunities
            }
            
        # Trigger adaptation if needed
        if quality_analysis["needs_improvement"]:
            adaptation_result = self._trigger_adaptation(
                interaction_id, query, response, user_feedback, quality_analysis
            )
        else:
            adaptation_result = {"status": "no_adaptation_needed"}
            
        return {
            "interaction_id": interaction_id,
            "quality_analysis": quality_analysis,
            "improvement_opportunities": opportunities,
            "adaptation_result": adaptation_result,
            "needs_attention": quality_analysis["needs_improvement"]
        }
        
    def _trigger_adaptation(self, interaction_id: str, query: str, response: str,
                          user_feedback: Dict[str, Any], quality_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Trigger adaptation based on feedback analysis
        
        Args:
            interaction_id: Interaction identifier
            query: User query
            response: Model response
            user_feedback: User feedback
            quality_analysis: Quality analysis results
            
        Returns:
            Adaptation results
        """
        try:
            # Create feedback vector (simplified representation)
            if TORCH_AVAILABLE:
                # Convert feedback to vector representation
                feedback_vector = self._create_feedback_vector(
                    query, response, user_feedback, quality_analysis
                )
                
                # Calculate performance delta
                performance_delta = quality_analysis["quality_score"] - 0.5  # Baseline
                
                # Adapt model
                adaptation_loss = self.adaptive_module.adapt_to_feedback(
                    feedback_vector, performance_delta
                )
                
                self.self_improvement_stats["successful_adaptations"] += 1
                
                return {
                    "status": "adaptation_successful",
                    "adaptation_loss": adaptation_loss,
                    "performance_delta": performance_delta,
                    "feedback_vector_norm": torch.norm(feedback_vector).item() if TORCH_AVAILABLE else 0.0
                }
            else:
                return {"status": "adaptation_skipped", "reason": "torch_not_available"}
                
        except Exception as e:
            return {"status": "adaptation_failed", "error": str(e)}
            
    def _create_feedback_vector(self, query: str, response: str, 
                              user_feedback: Dict[str, Any], 
                              quality_analysis: Dict[str, Any]) -> torch.Tensor:
        """
        Create vector representation of feedback
        
        Args:
            query: User query
            response: Model response
            user_feedback: User feedback dictionary
            quality_analysis: Quality analysis results
            
        Returns:
            Feedback vector tensor
        """
        if not TORCH_AVAILABLE:
            return torch.tensor([0.0])
            
        # Simple vector creation (in practice, this would be more sophisticated)
        features = [
            quality_analysis.get("accuracy_rating", 0.5),
            quality_analysis.get("completeness_rating", 0.5),
            quality_analysis.get("helpfulness_rating", 0.5),
            len(query) / 1000.0,  # Normalized query length
            len(response) / 5000.0,  # Normalized response length
            float("correction" in user_feedback),  # Correction flag
            float("accuracy" in quality_analysis.get("issues", [])),  # Accuracy issue flag
            float("completeness" in quality_analysis.get("issues", [])),  # Completeness issue flag
        ]
        
        # Pad or truncate to model dimension
        while len(features) < self.model_dim:
            features.append(0.0)
        features = features[:self.model_dim]
        
        return torch.tensor(features, dtype=torch.float32)
        
    def get_self_improvement_stats(self) -> Dict[str, Any]:
        """
        Get self-improvement statistics
        
        Returns:
            Dictionary of statistics
        """
        return {
            "timestamp": time.time(),
            "stats": self.self_improvement_stats,
            "knowledge_base_size": len(self.knowledge_base),
            "interaction_history_size": len(self.interaction_history),
            "improvement_log_size": len(self.improvement_log),
            "adaptive_module_params": sum(p.numel() for p in self.adaptive_module.parameters()) if TORCH_AVAILABLE else 0
        }
        
    def export_learning_report(self, filepath: str) -> bool:
        """
        Export learning report to file
        
        Args:
            filepath: Path to export report
            
        Returns:
            True if successful, False otherwise
        """
        try:
            report = {
                "generated_at": datetime.now().isoformat(),
                "self_improvement_stats": self.get_self_improvement_stats(),
                "recent_interactions": dict(list(self.interaction_history.items())[-20:]),
                "recent_improvements": dict(list(self.improvement_log.items())[-10:])
            }
            
            with open(filepath, 'w') as f:
                json.dump(report, f, indent=2, default=str)
                
            print(f"‚úÖ Self-improvement report exported to {filepath}")
            return True
        except Exception as e:
            print(f"‚ùå Failed to export learning report: {e}")
            return False


def demo_self_improvement_engine():
    """Demonstrate self-improvement engine functionality"""
    print("üöÄ Demonstrating Self-Improvement Engine...")
    print("=" * 50)
    
    # Create self-improvement engine
    engine = SelfImprovementEngine(model_dim=768)
    print("‚úÖ Created self-improvement engine")
    
    # Simulate user interactions
    print("\nüí¨ Simulating user interactions...")
    
    sample_interactions = [
        {
            "id": "int_001",
            "query": "What is machine learning?",
            "response": "Machine learning is a type of artificial intelligence that allows computers to learn from data.",
            "feedback": {
                "accuracy": 0.8,
                "completeness": 0.6,
                "helpfulness": 0.7,
                "comment": "Good basic explanation but could be more detailed"
            }
        },
        {
            "id": "int_002",
            "query": "How does a neural network work?",
            "response": "Neural networks are complex and I'm not sure about the exact details.",
            "feedback": {
                "accuracy": 0.4,
                "completeness": 0.3,
                "helpfulness": 0.2,
                "correction": "Neural networks consist of layers of interconnected nodes that process information."
            }
        },
        {
            "id": "int_003",
            "query": "Explain transformer architecture",
            "response": "Transformers use attention mechanisms to process sequences in parallel.",
            "feedback": {
                "accuracy": 0.9,
                "completeness": 0.8,
                "helpfulness": 0.9
            }
        }
    ]
    
    # Process interactions
    for interaction in sample_interactions:
        result = engine.process_user_interaction(
            interaction["id"],
            interaction["query"],
            interaction["response"],
            interaction["feedback"]
        )
        
        print(f"   Processed interaction {interaction['id']}:")
        print(f"     Quality score: {result['quality_analysis']['quality_score']:.2f}")
        print(f"     Issues found: {len(result['improvement_opportunities'])}")
        print(f"     Needs attention: {result['needs_attention']}")
        
    # Show statistics
    print("\nüìä Self-Improvement Statistics:")
    stats = engine.get_self_improvement_stats()
    print(f"   Total interactions: {stats['stats']['total_interactions']}")
    print(f"   Improvement opportunities: {stats['stats']['improvement_opportunities']}")
    print(f"   Successful adaptations: {stats['stats']['successful_adaptations']}")
    print(f"   Average quality score: {stats['stats']['feedback_quality_score']:.2f}")
    
    # Export report
    report_success = engine.export_learning_report("self_improvement_report.json")
    print(f"   Report export: {'SUCCESS' if report_success else 'FAILED'}")
    
    print("\n" + "=" * 50)
    print("SELF-IMPROVEMENT ENGINE DEMO SUMMARY")
    print("=" * 50)
    print("Key Features Implemented:")
    print("  1. Automated feedback analysis")
    print("  2. Improvement opportunity identification")
    print("  3. Adaptive learning from user interactions")
    print("  4. Performance tracking and statistics")
    print("  5. Comprehensive reporting")
    print("\nBenefits:")
    print("  - Continuous self-improvement from user feedback")
    print("  - Automated quality assessment")
    print("  - Targeted improvement opportunities")
    print("  - Adaptive response optimization")
    
    print("\n‚úÖ Self-improvement engine demonstration completed!")


if __name__ == "__main__":
    demo_self_improvement_engine()